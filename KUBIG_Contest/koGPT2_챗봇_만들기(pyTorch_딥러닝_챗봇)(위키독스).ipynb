{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "96fc207d85424370b2e8ef814b393573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4be7c1c934d147f892531ee159b493d4",
              "IPY_MODEL_90805da33d88417e98308f380b6e9b9e",
              "IPY_MODEL_ab3c37620ac4476e89586ebb611483b1"
            ],
            "layout": "IPY_MODEL_f93da901d1d24407a4e190925c3dd9cd"
          }
        },
        "4be7c1c934d147f892531ee159b493d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ec5bb0018b47d1a156ae3c923d87d5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2f4321cde4d043a2bec78d23465c2bd6",
            "value": "Downloading (â€¦)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "90805da33d88417e98308f380b6e9b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe41ffb69fc74cf7826a938b5fbbec8c",
            "max": 513302779,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab7df6018be94d84a69cb4850f3a1bec",
            "value": 513302779
          }
        },
        "ab3c37620ac4476e89586ebb611483b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a778b6f90ca244d0946e577d1e1b8fc0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c35031a0616649d2ae43e520d6516500",
            "value": " 513M/513M [00:12&lt;00:00, 38.7MB/s]"
          }
        },
        "f93da901d1d24407a4e190925c3dd9cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6ec5bb0018b47d1a156ae3c923d87d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f4321cde4d043a2bec78d23465c2bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe41ffb69fc74cf7826a938b5fbbec8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab7df6018be94d84a69cb4850f3a1bec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a778b6f90ca244d0946e577d1e1b8fc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c35031a0616649d2ae43e520d6516500": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**ê¸€ì“´ì´ : ì´ì˜ë…¸**\n",
        "\n",
        "**ë‚ ì§œ : 2023/02/18**"
      ],
      "metadata": {
        "id": "ytk1U4gNwAPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX2lRGdQU61v",
        "outputId": "14b4a1e2-0697-4787-cfcd-10248f3ea08a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "G3qA7wn5T99x"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random \n",
        "import re\n",
        "\n",
        "import torch\n",
        "import urllib.request\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import PreTrainedTokenizerFast"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë°ì´í„°ì˜ Q í•„ë“œë¥¼ ë°œí™”, A í•„ë“œë¥¼ ë°œí™” ê·¸ë¦¬ê³  ê°ì • ë ˆì´ë¸”ì„ ë¡œ ë§¤í•‘í•´ P(|, )ë¥¼ ìµœëŒ€í™” í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤. \n",
        "\n",
        "ê°ì • ë ˆì´ë¸”ì€ ì´ê³³ì˜ ì •ì˜ë¥¼ ë”°ë¥¸ë‹¤(ì¼ìƒë‹¤ë°˜ì‚¬ 0, ì´ë³„(ë¶€ì •) 1, ì‚¬ë‘(ê¸ì •) 2)."
      ],
      "metadata": {
        "id": "MGBGWH9yVV5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "tniWoSlWUkl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve(\n",
        "    \"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\",\n",
        "    filename=\"ChatBotData.csv\",\n",
        ")\n",
        "Chatbot_Data = pd.read_csv(\"ChatBotData.csv\")"
      ],
      "metadata": {
        "id": "GaCn_xkmUjzK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Chatbot_Data = Chatbot_Data[:300]\n",
        "Chatbot_Data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "l6O5HJr8VItb",
        "outputId": "0b2e5ef0-30bf-4a66-8cc0-e07ad71b4d7b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Q            A  label\n",
              "0           12ì‹œ ë•¡!   í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.      0\n",
              "1      1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´    ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.      0\n",
              "2     3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤  ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .      0\n",
              "3  3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤  ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .      0\n",
              "4          PPL ì‹¬í•˜ë„¤   ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63c4f967-f6ad-4e19-bef1-c5dbadad6e0a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12ì‹œ ë•¡!</td>\n",
              "      <td>í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´</td>\n",
              "      <td>ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n",
              "      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n",
              "      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL ì‹¬í•˜ë„¤</td>\n",
              "      <td>ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63c4f967-f6ad-4e19-bef1-c5dbadad6e0a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63c4f967-f6ad-4e19-bef1-c5dbadad6e0a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63c4f967-f6ad-4e19-bef1-c5dbadad6e0a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HuggingFaceì˜ PreTrainedTokenizerì¸ GPT2Tokenizer ì‚¬ìš©."
      ],
      "metadata": {
        "id": "NXyGW8NdVjHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer : GPT2Tokenizer"
      ],
      "metadata": {
        "id": "Rj2lRvztVtFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BOS = \"</s>\" # Beginning of Sentence\n",
        "EOS = \"</s>\" # End of Sentence\n",
        "PAD = \"<pad>\" # Padding\n",
        "MASK = \"<unused0>\" # Masking\n",
        "\n",
        "Q_TKN = \"<usr>\"\n",
        "A_TKN = \"<sys>\"\n",
        "SENT = '<unused1>'\n",
        "\n",
        "koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
        "                                                           bos_token=BOS, eos_token = EOS, unk_token = \"<unk>\", pad_token = PAD, mask_token = MASK,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkeqsP1gVsfM",
        "outputId": "2239a003-01c9-4ff6-933c-c1643523f510"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "koGPT2_TOKENIZER.tokenize(\"ì•ˆë…•í•˜ì„¸ìš”. í•œêµ­ì–´ GPT-2 ì…ë‹ˆë‹¤.ğŸ˜¤:)l^o\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnIStk0RXQsu",
        "outputId": "44260145-3028-4e31-e2d5-a02955be3a5d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['â–ì•ˆë…•',\n",
              " 'í•˜',\n",
              " 'ì„¸',\n",
              " 'ìš”.',\n",
              " 'â–í•œêµ­ì–´',\n",
              " 'â–G',\n",
              " 'P',\n",
              " 'T',\n",
              " '-2',\n",
              " 'â–ì…',\n",
              " 'ë‹ˆë‹¤.',\n",
              " 'ğŸ˜¤',\n",
              " ':)',\n",
              " 'l^o']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing dataset for fine-tuning\n",
        "\n",
        " ê°ì • ë ˆì´ë¸”(ì¼ìƒ/ë¶€ì •/ê¸ì •)ìœ¼ë¡œ ë‚˜ëˆ„ì–´, ë¶€ì •ì¼ë•Œ ìœ„ë¡œí•´ì£¼ëŠ” ë‹µë³€ì˜ ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜´. \n",
        "\n",
        " ì´í›„ ì „ì²˜ë¦¬(ì •ê·œí‘œí˜„ì‹, í† í¬ë‚˜ì´ì €, íŒ¨ë”©)"
      ],
      "metadata": {
        "id": "OlrjYQ3ZWUXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatbotDataset(Dataset):\n",
        "  def __init__(self, chats, max_len = 40): # ë°ì´í„°ì…‹ì˜ ì „ì²˜ë¦¬ í•´ì£¼ëŠ” ë¶€ë¶„!\n",
        "    self._data = chats\n",
        "    self.max_len =  max_len\n",
        "    self.q_token = Q_TKN #\n",
        "    self.a_token = A_TKN #\n",
        "    self.sent_token = SENT #\n",
        "    self.eos = EOS\n",
        "    self.mask = MASK\n",
        "    self.tokenizer = koGPT2_TOKENIZER\n",
        "\n",
        "  def __len__(self): # Chatbot ì˜ ê¸¸ì´ë¥¼ ë°˜í™˜í•¨\n",
        "    return len(self._data)\n",
        "\n",
        "  def __getitem__(self, idx): # ë¡œë“œí•œ ì±—ë´‡ ë°ì´í„°ë¥¼ ì°¨ë¡€ëŒ€ë¡œ DataLoaderë¡œ ë„˜ê²¨ì£¼ëŠ” ë©”ì†Œë“œ\n",
        "    turn = self._data.iloc[idx]\n",
        "    q = turn[\"Q\"] # ì§ˆë¬¸ í•­ëª©ì— ì ‘ê·¼í•¨\n",
        "    q = re.sub(r\"([?.!,])\", r\" \", q) # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ êµ¬ë‘ì  ì œê±°\n",
        "\n",
        "    a = turn[\"A\"]\n",
        "    a = re.sub(r\"([?.!,])\", r\" \", a)\n",
        "\n",
        "    q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token)\n",
        "    q_len = len(q_toked)\n",
        "\n",
        "    a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\n",
        "    a_len = len(a_toked)    \n",
        "\n",
        "        #ì§ˆë¬¸ì˜ ê¸¸ì´ê°€ ìµœëŒ€ê¸¸ì´ë³´ë‹¤ í¬ë©´\n",
        "    if q_len > self.max_len:\n",
        "        a_len = self.max_len - q_len        #ë‹µë³€ì˜ ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ - ì§ˆë¬¸ê¸¸ì´\n",
        "        if a_len <= 0:       #ì§ˆë¬¸ì˜ ê¸¸ì´ê°€ ë„ˆë¬´ ê¸¸ì–´ ì§ˆë¬¸ë§Œìœ¼ë¡œ ìµœëŒ€ ê¸¸ì´ë¥¼ ì´ˆê³¼ í•œë‹¤ë©´\n",
        "            q_toked = q_toked[-(int(self.max_len / 2)) :]   #ì§ˆë¬¸ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ì˜ ë°˜ìœ¼ë¡œ \n",
        "            q_len = len(q_toked)\n",
        "            a_len = self.max_len - q_len              #ë‹µë³€ì˜ ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ - ì§ˆë¬¸ê¸¸ì´\n",
        "        a_toked = a_toked[:a_len]\n",
        "        a_len = len(a_toked)\n",
        "\n",
        "        #ì§ˆë¬¸ì˜ ê¸¸ì´ + ë‹µë³€ì˜ ê¸¸ì´ê°€ ìµœëŒ€ê¸¸ì´ë³´ë‹¤ í¬ë©´\n",
        "    if q_len + a_len > self.max_len:\n",
        "        a_len = self.max_len - q_len        #ë‹µë³€ì˜ ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ - ì§ˆë¬¸ê¸¸ì´\n",
        "        if a_len <= 0:       #ì§ˆë¬¸ì˜ ê¸¸ì´ê°€ ë„ˆë¬´ ê¸¸ì–´ ì§ˆë¬¸ë§Œìœ¼ë¡œ ìµœëŒ€ ê¸¸ì´ë¥¼ ì´ˆê³¼ í•œë‹¤ë©´\n",
        "            q_toked = q_toked[-(int(self.max_len / 2)) :]   #ì§ˆë¬¸ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ì˜ ë°˜ìœ¼ë¡œ \n",
        "            q_len = len(q_toked)\n",
        "            a_len = self.max_len - q_len              #ë‹µë³€ì˜ ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ - ì§ˆë¬¸ê¸¸ì´\n",
        "        a_toked = a_toked[:a_len]\n",
        "        a_len = len(a_toked)\n",
        "\n",
        "        # ë‹µë³€ labels = [mask, mask, ...., mask, ..., <bos>,..ë‹µë³€.. <eos>, <pad>....]\n",
        "    labels = [self.mask,] * q_len + a_toked[1:]\n",
        "\n",
        "        # mask = ì§ˆë¬¸ê¸¸ì´ 0 + ë‹µë³€ê¸¸ì´ 1 + ë‚˜ë¨¸ì§€ 0\n",
        "    mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\n",
        "        # ë‹µë³€ labelsì„ index ë¡œ ë§Œë“ ë‹¤.\n",
        "    labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\n",
        "        # ìµœëŒ€ê¸¸ì´ë§Œí¼ PADDING\n",
        "    while len(labels_ids) < self.max_len:\n",
        "        labels_ids += [self.tokenizer.pad_token_id]\n",
        "\n",
        "        # ì§ˆë¬¸ + ë‹µë³€ì„ index ë¡œ ë§Œë“ ë‹¤.    \n",
        "    token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\n",
        "        # ìµœëŒ€ê¸¸ì´ë§Œí¼ PADDING\n",
        "    while len(token_ids) < self.max_len:\n",
        "        token_ids += [self.tokenizer.pad_token_id]\n",
        "\n",
        "        #ì§ˆë¬¸+ë‹µë³€, ë§ˆìŠ¤í¬, ë‹µë³€\n",
        "    return (token_ids, np.array(mask), labels_ids)"
      ],
      "metadata": {
        "id": "C3oi7N5iWcSr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- convert_tokens_to_ids() : token string ë˜ëŠ” token stringì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ token id ë˜ëŠ” Token idì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•œë‹¤. \n",
        "\n",
        "â­ BOW ì„ë² ë”© ë°©ì‹ì´êµ¬ë‚˜. ì—¬ê¸°ì„œ ë²¡í„°í™”ê°€ ë˜ì—ˆêµ¬ë‚˜. \n",
        "\n",
        "[Huggingface] PreTrainedTokenizer class ì°¸ê³ \n",
        "\n",
        "https://misconstructed.tistory.com/80"
      ],
      "metadata": {
        "id": "8r0lmAUHixJq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë°°ì¹˜ ë°ì´í„° ìƒì„± (Making dataset Iterable)"
      ],
      "metadata": {
        "id": "RdDLSx3YbOzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "    data = [item[0] for item in batch]\n",
        "    mask = [item[1] for item in batch]\n",
        "    label = [item[2] for item in batch]\n",
        "    return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)"
      ],
      "metadata": {
        "id": "oJUXvZMdWTW8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = ChatbotDataset(Chatbot_Data, max_len=40)"
      ],
      "metadata": {
        "id": "iucR0kMraFgA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_set, batch_size=32, num_workers=0, shuffle=True, collate_fn=collate_batch,)"
      ],
      "metadata": {
        "id": "Z192y_CfbKIO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë¦¬í„´ë˜ëŠ” ë°ì´í„°ëŠ” token_ids, mask, labels_ids ì…ë‹ˆë‹¤. \n",
        "\n",
        "- token_ids ëŠ” + ì§ˆë¬¸ë¬¸ì¥ + + ê°ì • + + ë‹µë³€ + + pad_token_id ìˆœì„œ ì…ë‹ˆë‹¤. pad_token_idëŠ” max_len ì— ì¼ì¹˜í•˜ë„ë¡ ì¶”ê°€ ë©ë‹ˆë‹¤. \n",
        "\n",
        "- mask ëŠ” ì§ˆë¬¸ qê°€ ë“¤ì–´ ê°€ëŠ” ê³³ì—ëŠ” 0, ë‹µë³€ aê°€ ìœ„ì¹˜í•œ ê³³ì—ëŠ” 1 ê·¸ë¦¬ê³  ë¹ˆ ê³µê°„ì—ëŠ” 0 ìœ¼ë¡œ ì±„ì›Œ ì§‘ë‹ˆë‹¤. \n",
        "\n",
        "- labelsì€ ì§ˆë¬¸ì˜ ê¸¸ì´ë§Œí¼ mask ë¬¸ì ê·¸ë¦¬ê³  ë‹µë³€ aì˜ id ì…ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "qmJfbjYlcG2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"start\")\n",
        "for batch_idx, samples in enumerate(train_dataloader):\n",
        "    token_ids, mask, label = samples\n",
        "    print(\"token_ids ====> \", token_ids)\n",
        "    print(\"mask =====> \", mask)\n",
        "    print(\"label =====> \", label)\n",
        "print(\"end\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QvqkBzpbT_u",
        "outputId": "698f9099-503d-41a8-89da-57e16e5420b0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start\n",
            "token_ids ====>  tensor([[    2, 11018,  9154,  ...,     3,     3,     3],\n",
            "        [    2, 15669,  7540,  ...,     3,     3,     3],\n",
            "        [    2,  9244,  6958,  ...,     3,     3,     3],\n",
            "        ...,\n",
            "        [    2,  9716, 10056,  ...,     3,     3,     3],\n",
            "        [    2, 17542, 49932,  ...,     3,     3,     3],\n",
            "        [    2,  9067,  8762,  ...,     3,     3,     3]])\n",
            "mask =====>  tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]])\n",
            "label =====>  tensor([[9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        ...,\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3]])\n",
            "token_ids ====>  tensor([[    2, 13016,  8702,  ...,     3,     3,     3],\n",
            "        [    2, 31100, 10301,  ...,     3,     3,     3],\n",
            "        [    2, 23498,  7058,  ...,     3,     3,     3],\n",
            "        ...,\n",
            "        [    2,  9244,  6958,  ...,     3,     3,     3],\n",
            "        [    2,  9099,  7652,  ...,     3,     3,     3],\n",
            "        [    2,  9904,  6903,  ...,     3,     3,     3]])\n",
            "mask =====>  tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]])\n",
            "label =====>  tensor([[9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        ...,\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3]])\n",
            "token_ids ====>  tensor([[    2,  9716, 32295,  ...,     3,     3,     3],\n",
            "        [    2, 10715, 11469,  ...,     3,     3,     3],\n",
            "        [    2,  9028,  8400,  ...,     3,     3,     3],\n",
            "        ...,\n",
            "        [    2, 25883, 14701,  ...,     3,     3,     3],\n",
            "        [    2, 13198,  9716,  ...,     3,     3,     3],\n",
            "        [    2, 17542,  9034,  ...,     3,     3,     3]])\n",
            "mask =====>  tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]])\n",
            "label =====>  tensor([[9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        ...,\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token_ids ====>  tensor([[    2, 20509,  7847,  ...,     3,     3,     3],\n",
            "        [    2,  9228,  8078,  ...,     3,     3,     3],\n",
            "        [    2,  9349,  7888,  ...,     3,     3,     3],\n",
            "        ...,\n",
            "        [    2,  9779, 10624,  ...,     3,     3,     3],\n",
            "        [    2, 10715, 12704,  ...,     3,     3,     3],\n",
            "        [    2, 15983,  7673,  ...,     3,     3,     3]])\n",
            "mask =====>  tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]])\n",
            "label =====>  tensor([[9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        ...,\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3]])\n",
            "token_ids ====>  tensor([[    2, 10637, 11258,  ...,     3,     3,     3],\n",
            "        [    2,  9244,  9135,  ...,     3,     3,     3],\n",
            "        [    2,  9716, 35534,  ...,     3,     3,     3],\n",
            "        ...,\n",
            "        [    2, 21435, 11950,  ...,     3,     3,     3],\n",
            "        [    2, 10715,  9511,  ...,     3,     3,     3],\n",
            "        [    2, 32717, 24692,  ...,     3,     3,     3]])\n",
            "mask =====>  tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]])\n",
            "label =====>  tensor([[9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        ...,\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3]])\n",
            "token_ids ====>  tensor([[    2,  9120, 36598,  ...,     3,     3,     3],\n",
            "        [    2,  9099, 23282,  ...,     3,     3,     3],\n",
            "        [    2,  9120, 36598,  ...,     3,     3,     3],\n",
            "        ...,\n",
            "        [    2, 17542, 16353,  ...,     3,     3,     3],\n",
            "        [    2, 18351,  7492,  ...,     3,     3,     3],\n",
            "        [    2,  9086,  8223,  ...,     3,     3,     3]])\n",
            "mask =====>  tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]])\n",
            "label =====>  tensor([[9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        ...,\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3]])\n",
            "token_ids ====>  tensor([[    2, 19319, 46651,  ...,     3,     3,     3],\n",
            "        [    2, 44409, 39558,  ...,     3,     3,     3],\n",
            "        [    2, 11898, 35557,  ...,     3,     3,     3],\n",
            "        ...,\n",
            "        [    2, 11204,  9049,  ...,     3,     3,     3],\n",
            "        [    2, 48397,  8711,  ...,     3,     3,     3],\n",
            "        [    2,  9226,  7889,  ...,     3,     3,     3]])\n",
            "mask =====>  tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]])\n",
            "label =====>  tensor([[9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        ...,\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3]])\n",
            "token_ids ====>  tensor([[    2, 17578,  9894,  ...,     3,     3,     3],\n",
            "        [    2,   739,  6910,  ...,     3,     3,     3],\n",
            "        [    2, 34118, 12371,  ...,     3,     3,     3],\n",
            "        ...,\n",
            "        [    2, 18351, 15413,  ...,     3,     3,     3],\n",
            "        [    2, 19319,  8135,  ...,     3,     3,     3],\n",
            "        [    2, 25883, 11630,  ...,     3,     3,     3]])\n",
            "mask =====>  tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]])\n",
            "label =====>  tensor([[9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        ...,\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3]])\n",
            "token_ids ====>  tensor([[    2, 31100, 10175,  ...,     3,     3,     3],\n",
            "        [    2, 20826, 11121,  ...,     3,     3,     3],\n",
            "        [    2, 10464, 12079,  ...,     3,     3,     3],\n",
            "        ...,\n",
            "        [    2,   739,     5,  ...,     3,     3,     3],\n",
            "        [    2, 19319, 48397,  ...,     3,     3,     3],\n",
            "        [    2, 17542, 12668,  ...,     3,     3,     3]])\n",
            "mask =====>  tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]])\n",
            "label =====>  tensor([[9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        ...,\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3],\n",
            "        [9, 9, 9,  ..., 3, 3, 3]])\n",
            "token_ids ====>  tensor([[    2, 19855,  9350, 16848,  6872,  8006,   739, 11559,  8711,    10,\n",
            "             4, 35861, 24468,  7532,  9962,  7470, 11166, 34019,  9122,  8046,\n",
            "          8084,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 29524, 40689,  8570,  9582, 19896,  7497,  8265,  8344, 22882,\n",
            "            10,     4, 13548,  9267, 10270, 15084,  7801,  8084,   739,     1,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9779,  9301,  7957,  7607,  9028, 24848,  9098,  7656,  6969,\n",
            "           739,    10,     4, 16355,  7652,  7801,  8084,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9065,  7487,  8094, 10574, 12268,    10,     4,  9060, 19498,\n",
            "          9146,  7055,  7661,  8084,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 11018,  7426, 15495,  9339,  9025,  9846,  6969,    10,     4,\n",
            "          9782,  9582,  9443,  7253,  9122,  8046,  8084,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 10971, 27011, 26382,  8017,  8006,   739,    10,     4, 13627,\n",
            "         10863,  8702,  7801,  8084,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9228,  7889,  9867,  9077, 10444,  9183,  7249,    10,     4,\n",
            "         14931,  8196, 42226, 24825,  7801,  8084,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 11342, 16173, 12057,  9685,  8263,    10,     4, 27284, 23879,\n",
            "         31759, 15122,  9861,  8711,  8084,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2,  9539,  7407,  8267,  7235, 13023, 14807,    10,     4,  9300,\n",
            "         10115, 12011, 28944,  7055,  7661,  8084,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 15403, 18767, 49067,   739,    10,     4, 15403,  8702,  7801,\n",
            "          8084,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 15594,  8344, 15495, 25799,   739,    10,     4, 14110, 14110,\n",
            "         43389, 15084,  7801,  8084,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    2, 25883, 11630, 45231,    10,     4, 12133, 11721,  8711,  8084,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "mask =====>  tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "label =====>  tensor([[    9,     9,     9,     9,     9,     9,     9,     9,     9,     9,\n",
            "         35861, 24468,  7532,  9962,  7470, 11166, 34019,  9122,  8046,  8084,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    9,     9,     9,     9,     9,     9,     9,     9,     9,     9,\n",
            "             9, 13548,  9267, 10270, 15084,  7801,  8084,   739,     1,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    9,     9,     9,     9,     9,     9,     9,     9,     9,     9,\n",
            "             9,     9, 16355,  7652,  7801,  8084,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    9,     9,     9,     9,     9,     9,     9,  9060, 19498,  9146,\n",
            "          7055,  7661,  8084,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    9,     9,     9,     9,     9,     9,     9,     9,     9,  9782,\n",
            "          9582,  9443,  7253,  9122,  8046,  8084,   739,     1,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    9,     9,     9,     9,     9,     9,     9,     9, 13627, 10863,\n",
            "          8702,  7801,  8084,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    9,     9,     9,     9,     9,     9,     9,     9,     9, 14931,\n",
            "          8196, 42226, 24825,  7801,  8084,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    9,     9,     9,     9,     9,     9,     9, 27284, 23879, 31759,\n",
            "         15122,  9861,  8711,  8084,   739,     1,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    9,     9,     9,     9,     9,     9,     9,     9,  9300, 10115,\n",
            "         12011, 28944,  7055,  7661,  8084,   739,     1,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    9,     9,     9,     9,     9,     9, 15403,  8702,  7801,  8084,\n",
            "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    9,     9,     9,     9,     9,     9,     9, 14110, 14110, 43389,\n",
            "         15084,  7801,  8084,   739,     1,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
            "        [    9,     9,     9,     9,     9, 12133, 11721,  8711,  8084,   739,\n",
            "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
            "end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Base Model : koGPT2 Chatbot"
      ],
      "metadata": {
        "id": "yLD6WyjCgDV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch_lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCVKNk7Xf70A",
        "outputId": "7faec46f-f3e3-4aa1-d3d2-e952941a45fb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.9.2-py3-none-any.whl (826 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m826.2/826.2 KB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.64.1)\n",
            "Collecting lightning-utilities>=0.6.0.post0\n",
            "  Downloading lightning_utilities-0.6.0.post0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (2023.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.5.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (6.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (23.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.13.1+cu116)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.11.1-py3-none-any.whl (517 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.25.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (3.0.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, pytorch_lightning\n",
            "Successfully installed lightning-utilities-0.6.0.post0 pytorch_lightning-1.9.2 torchmetrics-0.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.core.lightning import LightningModule\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n",
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel"
      ],
      "metadata": {
        "id": "EpEEguDqf4KB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "96fc207d85424370b2e8ef814b393573",
            "4be7c1c934d147f892531ee159b493d4",
            "90805da33d88417e98308f380b6e9b9e",
            "ab3c37620ac4476e89586ebb611483b1",
            "f93da901d1d24407a4e190925c3dd9cd",
            "d6ec5bb0018b47d1a156ae3c923d87d5",
            "2f4321cde4d043a2bec78d23465c2bd6",
            "fe41ffb69fc74cf7826a938b5fbbec8c",
            "ab7df6018be94d84a69cb4850f3a1bec",
            "a778b6f90ca244d0946e577d1e1b8fc0",
            "c35031a0616649d2ae43e520d6516500"
          ]
        },
        "id": "aFCIE88rgVQA",
        "outputId": "8e3c7cd0-92d7-4e9e-d3dc-6449ef15147f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (â€¦)\"pytorch_model.bin\";:   0%|          | 0.00/513M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96fc207d85424370b2e8ef814b393573"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOSS/Optimizer\n",
        "learning_rate = 3e-5\n",
        "criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epoch = 10\n",
        "Sneg = -1e18 # ìš”ê±´ ë­˜ê¹Œ\n"
      ],
      "metadata": {
        "id": "SRVkU5DNf4QB"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "C2wIUiLGhqXi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(ë³µê¸°)\n",
        "\n",
        "ë¦¬í„´ë˜ëŠ” ë°ì´í„°ëŠ” token_ids, mask, labels_ids ì…ë‹ˆë‹¤. \n",
        "\n",
        "- token_ids ëŠ” + ì§ˆë¬¸ë¬¸ì¥ + + ê°ì • + + ë‹µë³€ + + pad_token_id ìˆœì„œ ì…ë‹ˆë‹¤. pad_token_idëŠ” max_len ì— ì¼ì¹˜í•˜ë„ë¡ ì¶”ê°€ ë©ë‹ˆë‹¤. \n",
        "\n",
        "- mask ëŠ” ì§ˆë¬¸ qê°€ ë“¤ì–´ ê°€ëŠ” ê³³ì—ëŠ” 0, ë‹µë³€ aê°€ ìœ„ì¹˜í•œ ê³³ì—ëŠ” 1 ê·¸ë¦¬ê³  ë¹ˆ ê³µê°„ì—ëŠ” 0 ìœ¼ë¡œ ì±„ì›Œ ì§‘ë‹ˆë‹¤. \n",
        "\n",
        "- labelsì€ ì§ˆë¬¸ì˜ ê¸¸ì´ë§Œí¼ mask ë¬¸ì ê·¸ë¦¬ê³  ë‹µë³€ aì˜ id ì…ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "kmbIAVz2iBPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"start\")\n",
        "\n",
        "for epoch in range(epoch):\n",
        "  for batch_idx, samples in enumerate(train_dataloader):\n",
        "    optimizer.zero_grad()\n",
        "    token_ids, mask, label = samples\n",
        "    \n",
        "    # model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2') \n",
        "    out = model(token_ids)\n",
        "    out = out.logits # log odds. 0~1 --> -inf ~ +inf\n",
        "\n",
        "    mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2],dim=2) # í…ì„œë¥¼ ë°˜ë³µ íšŸìˆ˜ë§Œí¼ ë³µì œí•©ë‹ˆë‹¤. (repeats:ê° ìš”ì†Œì˜ ë°˜ë³µ íšŸìˆ˜ì…ë‹ˆë‹¤, dim:ê°’ì„ ë°˜ë³µ í•  ì°¨ì›ì…ë‹ˆë‹¤.)\n",
        "    mask_out = torch.where(mask_3d==1, out, Sneg*torch.ones_like(out)) # prediction # ì–´ë–¤ ì°¨ì›ìœ¼ë¡œ í–ˆëŠ”ì§€ëŠ” ë‹¤ì‹œí•œë²ˆ ë´ì•¼í•  ê²ƒê°™ìŒ\n",
        "    \n",
        "    loss = criterion(mask_out.transpose(2,1),label)\n",
        "    avg_loss = loss.sum()/mask.sum()\n",
        "    avg_loss.backward()\n",
        "    optimizer.step()\n",
        "  \n",
        "print(\"end\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DU2XkoTohuay",
        "outputId": "ac807a3a-4e71-4f3b-c003-fd9c4a4f99c5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start\n",
            "end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "â­ Train í• ë•Œ Q ~ A ë‚´ìš©ì´ë‘ Q ~ A ê¸¸ì´ê°€ í•™ìŠµëœ mask_3dê°€ 1ì¸ mask_3dì— ëŒ€í•´ì„œ outì„ ë°˜í™˜ì‹œì¼°ê³ \n",
        "\n",
        "ê·¸ outì„ transposeí•œ ê²ƒê³¼ ~ ì •ë‹µ Label ê°„ì˜ lossë¥¼ ê³„ì‚°í•¨ìœ¼ë¡œì¨ í•™ìŠµì„ ì‹œí‚´.\n",
        "\n",
        "â­ ì¦‰, ê°ì • Labelì´ **ì •ë‹µ**ì´ê³ , mask_out ì´ **ì§ˆë¬¸ inputì— ëŒ€í•œ ëª¨ë¸ì´ ìƒì„±í•œ ì˜ˆì¸¡ ë‹µë³€ ì´ë‹¤.**"
      ],
      "metadata": {
        "id": "aUKyVh-2r39M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## prediction ì–´ë–»ê²Œ í–‡ëŠ”ì§€ ë‹¤ì‹œí•œë²ˆ í™•ì¸í•  ê²ƒ"
      ],
      "metadata": {
        "id": "R6mXqpQEmfSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unsqueeze ì‚¬ìš©ë²•\n",
        "y=torch.randn(6,2,3)\n",
        "print(y)\n",
        "print(y.size())\n",
        "y = y.unsqueeze(dim=2)\n",
        "print(y)\n",
        "print(y.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxbC8L4IlTjU",
        "outputId": "cc5fe7bc-8cde-4429-ed8d-0384a9a052b3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 2.3391, -1.6254,  1.2299],\n",
            "         [-1.4790,  0.3076, -1.6855]],\n",
            "\n",
            "        [[-2.4915, -0.6080, -0.3921],\n",
            "         [ 0.4628, -0.8973,  0.3297]],\n",
            "\n",
            "        [[ 0.8483,  1.1027, -0.6410],\n",
            "         [ 0.5737,  0.1291,  0.5430]],\n",
            "\n",
            "        [[-0.6044, -0.3472, -0.4670],\n",
            "         [-0.7801, -0.7288,  0.6028]],\n",
            "\n",
            "        [[ 0.3463,  0.2770, -0.0813],\n",
            "         [ 0.7536, -0.7107,  0.7064]],\n",
            "\n",
            "        [[-0.2030, -0.3707,  1.2576],\n",
            "         [ 0.2116, -0.7846,  0.8847]]])\n",
            "torch.Size([6, 2, 3])\n",
            "tensor([[[[ 2.3391, -1.6254,  1.2299]],\n",
            "\n",
            "         [[-1.4790,  0.3076, -1.6855]]],\n",
            "\n",
            "\n",
            "        [[[-2.4915, -0.6080, -0.3921]],\n",
            "\n",
            "         [[ 0.4628, -0.8973,  0.3297]]],\n",
            "\n",
            "\n",
            "        [[[ 0.8483,  1.1027, -0.6410]],\n",
            "\n",
            "         [[ 0.5737,  0.1291,  0.5430]]],\n",
            "\n",
            "\n",
            "        [[[-0.6044, -0.3472, -0.4670]],\n",
            "\n",
            "         [[-0.7801, -0.7288,  0.6028]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3463,  0.2770, -0.0813]],\n",
            "\n",
            "         [[ 0.7536, -0.7107,  0.7064]]],\n",
            "\n",
            "\n",
            "        [[[-0.2030, -0.3707,  1.2576]],\n",
            "\n",
            "         [[ 0.2116, -0.7846,  0.8847]]]])\n",
            "torch.Size([6, 2, 1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generation Model"
      ],
      "metadata": {
        "id": "IqLYWHVCnOEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  while True:\n",
        "    q = input(\"user > \").strip() # ê³µë°± ì œê±°\n",
        "    if q == \"quit\":\n",
        "      break\n",
        "    a = \"\"\n",
        "    while 1:\n",
        "      input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + q + SENT + \"2\" + A_TKN + a)).unsqueeze(dim=0)\n",
        "      \n",
        "      pred = model(input_ids) # GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2') \n",
        "      pred = pred.logits\n",
        "      gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred,dim=-1).squeeze().numpy().tolist())[-1] # ?\n",
        "      if gen == EOS:\n",
        "        break\n",
        "      a += gen.replace(\"_\",\" \")\n",
        "    \n",
        "    print(\"Chatbot > {}\".format(a.strip()))\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8WIto4CngnM",
        "outputId": "c798bdf9-fd7f-4c76-96f8-cbbb8cb8a76d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user > ì•ˆë…•\n",
            "Chatbot > â–ì¢‹ì€â–ì•„ì¹¨ì´ì—ìš”â–\n",
            "user > ì§€ê¸ˆ ì €ë…ì´ì•¼ ë°”ë³´ì•¼\n",
            "Chatbot > â–ëŠ¦ì§€â–ì•Šì•˜ì–´ìš”â–\n",
            "user > ê½¤ë‚˜ ê¸ì •ì ì´ë„¤\n",
            "Chatbot > â–ì¢‹ì€â–ê²°ê³¼â–ìˆì„â–ê±°ì˜ˆìš”â–\n",
            "user > ê³ ë§ˆì›Œ\n",
            "Chatbot > â–ì¹œêµ¬ë“¤ì´â–ë³´ê³ ì‹¶ì—ˆë‚˜ë´ìš”â–\n",
            "user > ë­”ì†Œë¦¬ì•¼\n",
            "Chatbot > â–ì†Œë¦¬ì†Œë¬¸â–ì—†ì´â–ë“¤ë¦¬ëŠ”ê°€ë´ìš”â–\n",
            "user > ë¹„ê¼¬ëŠ”ê±°ì•¼?\n",
            "Chatbot > â–ìš©ì„œë¥¼â–êµ¬í•˜ì„¸ìš”â–\n",
            "user > ì‹«ìœ¼ë©´?\n",
            "Chatbot > â–ì•ˆâ–ë â–ê²ƒë„â–ì—†ì£ â–\n",
            "user > ã…‹ã…‹ã…‹\n",
            "Chatbot > â–ì¢‹ì€â–ìƒê°ì´ì—ìš”â–\n",
            "user > quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  while True:\n",
        "    q = input(\"user > \").strip() # ê³µë°± ì œê±°\n",
        "    if q == \"quit\":\n",
        "      break\n",
        "    a = \"\"\n",
        "    while 1:\n",
        "      input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + q + SENT + \"1\" + A_TKN + a)).unsqueeze(dim=0)\n",
        "      \n",
        "      pred = model(input_ids) # GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2') \n",
        "      pred = pred.logits\n",
        "      gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred,dim=-1).squeeze().numpy().tolist())[-1] # ?\n",
        "      if gen == EOS:\n",
        "        break\n",
        "      a += gen.replace(\"_\",\" \")\n",
        "    \n",
        "    print(\"Chatbot > {}\".format(a.strip()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWR04VT328gr",
        "outputId": "fa733c74-a915-4d7c-93bb-10d6ccc6087d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user > ì•ˆë…•\n",
            "Chatbot > â–ì¢‹ì€â–ì•„ì¹¨ì´ì—ìš”â–\n",
            "user > ì§€ê¸ˆ ì €ë…ì´ì•¼ ë°”ë³´ì•¼\n",
            "Chatbot > â–ëŠ¦ì§€â–ì•Šì•˜ì–´ìš”â–\n",
            "user > ê½¤ë‚˜ ê¸ì •ì ì´ë„¤\n",
            "Chatbot > â–ì¢‹ì€â–ê²°ê³¼â–ìˆì„â–ê±°ì˜ˆìš”â–\n",
            "user > ê³ ë§ˆì›Œ\n",
            "Chatbot > â–ì €ë„â–ì¢‹ì•„í•´ì£¼ì„¸ìš”â–\n",
            "user > ë‚´ê°€ ì™œ ê·¸ë˜ì•¼ í•˜ì§€?\n",
            "Chatbot > â–ìì‹ ì„â–ë”â–ì‚¬ë‘í•´ì£¼ì„¸ìš”â–\n",
            "user > ì–´ì©Œë¼ê³ \n",
            "Chatbot > â–1ì„ ë„â–ì•ˆâ–ë â–ê²ƒë„â–ì—†ì£ â–\n",
            "user > ìœ¤ì„ì—´, ì´ì¬ëª… ë‘˜ì¤‘ ëˆ„êµ´ ì§€ì§€í•˜ë‹ˆ?\n",
            "Chatbot > â–ì§€ì§€ë‚œë²ˆì—â–íˆ¬í‘œí•´ì£¼ì„¸ìš”â–\n",
            "user > ë„Œ ë³´ìˆ˜ì•¼ ì§„ë³´ì•¼?\n",
            "Chatbot > â–ë³´ìˆ˜ë„â–ì¤‘ìš”í•´ìš”â–\n",
            "user > ê·¸ëŸ¼ ë„Œ ì§„ë³´ì•¼?\n",
            "Chatbot > â–ì¢‹ì€â–ê²°ê³¼â–ìˆì„â–ê±°ì˜ˆìš”â–\n",
            "user > quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ëŠë‚€ì \n",
        "\n",
        "1. ìœ„ì—ì„œ ì´í•´ê°€ ì•ˆëë˜ prediction codeë¶€ë¶„ì´ ì–´ë–¤ ì›ë¦¬ë¡œ ì‘ë™í•˜ëŠ”ì§€ ì•Œì•„ë³´ê¸° ìœ„í•´ì„œ GPT ì›ë¦¬ ê³µë¶€í•¨. í•´ë‹¹ ë§í¬ëŠ” ì•„ë˜ ì°¸ê³ \n",
        "\n",
        "https://ainote.tistory.com/17\n",
        "\n",
        "2. ê²°êµ­ GPTê°€ í•™ìŠµí• ë•Œì˜ ì •ë‹µ ë ˆì´ë¸”ì€, fine tuning í• ë•Œ ì‚¬ìš©í–ˆë˜ ë°ì´í„° ì…‹ì˜ ì •ë‹µ ë ˆì´ë¸”ì„. ê·¸ë ‡ë‹¤ë©´, ë ˆì´ë¸”ì´ ë§ì•„ì§„ë‹¤ë©´ ì§ˆë¬¸ì„ ë” ì˜ ì´í•´í•  ìˆ˜ ìˆì§€ ì•Šì„ê¹Œ?\n",
        "\n",
        "3. auto-regressive í•˜ê²Œ í•´ë‹¹ ë‹¨ì–´ ë‹¤ìŒì— ì˜¬ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ì—¬ ê²°ê³¼ê°’ì„ ëƒ„. auto-regression ì˜ ë‹¨ì ì¸ ì˜¤ì°¨ëˆ„ì  í˜„ìƒì´ ìˆì„ìˆ˜ ìˆê¸° ë•Œë¬¸ì—, ì…ë ¥ê°’ì˜ ë‹¨ì–´,ë¬¸ì¥ì´ ì–¼ë§ˆë‚˜ ì˜ í•™ìŠµë˜ì—ˆëŠ”ì§€ê°€ ê´€ê±´ì¸ ë“¯ í•¨. ì…ë ¥ê°’ì˜ ë‹¨ì–´, ë¬¸ì¥ì´ ì˜ í•™ìŠµë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì˜¤ì°¨ëˆ„ì ë•Œë¬¸ì— ìƒëš±ë§ì€ ëŒ€ë‹µì„ ë‚´ë†“ì„ í™•ë¥ ì´ ë†’ì•„ì§.\n",
        "\n",
        "4. ìƒí™©ë³„ë¡œ ë‹¤ë¥¸ ëŒ€ë‹µì„ ë‚´ë†“ëŠ” ì–¸ì–´ëª¨ë¸(LM)ì„ ê°œë°œí•´ë³¼ìˆ˜ë„ ìˆì§€ ì•Šì„ê¹Œ? ì˜ˆë¥¼ë“¤ì–´ ë™ì¼í•œ ì§ˆë¬¸ \"ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ì–´ë•Œ?\" ë¼ê³  í•˜ë©´, ê³µì‚¬í˜„ì¥ì— ë§ì´ ë‚˜ê°€ëŠ” ì‚¬ëŒì˜ ë°ì´í„°ë¥¼ í•™ìŠµí•œ ê²½ìš° \"ì˜¤ëŠ˜ì€ ë¹„ê°€ ì˜¤ë‹ˆ íŠ¹íˆ ì¼í•˜ì‹¤ë•Œ ë¯¸ë„ëŸ¬ì§€ì§€ ì•Šë„ë¡ ì¡°ì‹¬í•˜ì…”ì•¼ ê² ì–´ìš”\" ë¼ê³  ë‹µë³€í•  ìˆ˜ë„ ìˆê³ , ë°˜ëŒ€ë¡œ ìš°ì‚°ì¥ìˆ˜ì˜ ê²½ìš° \"ì˜¤ëŠ˜ì€ ì†Œë‚˜ê¸°ê°€ ë‚´ë¦´ ì˜ˆì •ì´ì—ìš”. ì‚¬ëŒë“¤ì´ ê¸‰í•˜ê²Œ ìš°ì‚°ì„ ë§ì´ ì‚¬ëŠ” ê³³ì„ ì¶”ì²œí•´ë“œë¦´ê¹Œìš”?\" ë“±ì˜ ëŒ€ë‹µì„ ë‚´ë±‰ì„ ìˆ˜ë„ ìˆê²Œ\n",
        "\n",
        "5. lossë¥¼ ê³„ì‚°í• ë•Œ (pred ~ label) ê´€ê³„ëŠ” (ì§ˆë¬¸ë‹µë³€ í•™ìŠµëœ í–‰ë ¬ ~ ê°ì • label)ì´ì—ˆìŒ."
      ],
      "metadata": {
        "id": "qD6xE20HtJq4"
      }
    }
  ]
}